{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@id": "https://bio.tools/medical_relation_extraction",
  "@type": "sc:SoftwareApplication",
  "sc:description": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning.\n\nThe depository support training and testing BERT-CNN model on three medical relation extraction corpora: BioCreative V CDR task corpus, traditional Chinese medicine literature corpus, and i2b2 temporal relation corpus.\n\nThis is an implementation of BERT-CNN model used in our paper \"A General Approach for Improving Deep Learning-based Medical Relation Extraction using a Pre-trained Model and Fine-tuning\".\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'BERT'",
  "sc:license": "MIT",
  "sc:name": "medical relation extraction",
  "sc:url": "https://github.com/chentao1999/MedicalRelationExtraction"
}