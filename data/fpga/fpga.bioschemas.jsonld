{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.tools/FPGA",
      "@type": "sc:SoftwareApplication",
      "sc:applicationSubCategory": [
        {
          "@id": "edam:topic_3372"
        },
        {
          "@id": "edam:topic_3474"
        },
        {
          "@id": "edam:topic_3361"
        }
      ],
      "sc:citation": [
        {
          "@id": "https://doi.org/10.1371/JOURNAL.PONE.0222984"
        },
        "pubmed:31600218",
        "pmcid:PMC6786543"
      ],
      "sc:description": "Research on OpenCL optimization for FPGA deep learning application.\n\nOptimize the code provided by Xilinx, and the experiment proves that the optimized performance is 8-40 times optimized by Xilinx.The code URL provided by Xilinx is: https://github.com/Xilinx/SDAccel_Examples/tree/master/getting_started/clk_freq/large_loop_ocl Eight kinds Of convolution layer programs are set up by us according to the ascending order.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'OpenCL'",
      "sc:name": "FPGA",
      "sc:url": "https://github.com/PoetryAndWine/FPGA_CNN_Acceleration"
    },
    {
      "@id": "https://doi.org/10.1371/JOURNAL.PONE.0222984",
      "@type": "sc:CreativeWork"
    }
  ]
}